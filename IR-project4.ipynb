{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "result = list(Path(\"flaskblog\").rglob(\"*.json\"))\n",
    "for i in range(1,len(result)):\n",
    "    x = str(result[i])\n",
    "    print(x)\n",
    "    #print(x.replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "static = {}\n",
    "count_covid = 0\n",
    "count_non_covid = 0\n",
    "count_india = 0\n",
    "count_italy = 0\n",
    "count_usa = 0\n",
    "poi_names = {}\n",
    "for i in range(1,len(result)):\n",
    "    #print(result[i])\n",
    "    try:\n",
    "        x = str(result[i])\n",
    "        x = x.replace('\\\\','/')\n",
    "        with open(x,encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "        if 'JSON_IR_ROHIT' not in x:\n",
    "            data = data.replace('}{','},{')\n",
    "            data = '['+data+']'\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        else:\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        for post in posts:\n",
    "            if ('covid' or 'corona') in post['full_text'].lower():\n",
    "                count_covid+=1\n",
    "            else:\n",
    "                count_non_covid+=1\n",
    "                \n",
    "            if post['country'].lower()=='india':\n",
    "                count_india+=1\n",
    "            elif post['country'].lower()=='italy':\n",
    "                count_italy+=1\n",
    "            else:\n",
    "                count_usa+=1\n",
    "            if(post['user']['screen_name']!=None):\n",
    "                if post['user']['screen_name'].lower() not in poi_names:\n",
    "                    poi_names[post['user']['screen_name'].lower()]=1\n",
    "                else:\n",
    "                    poi_names[post['user']['screen_name'].lower()]+=1\n",
    "        f.close()\n",
    "    except:\n",
    "        print(x)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_covid)\n",
    "print(count_non_covid)\n",
    "print(poi_names)\n",
    "print(count_india)\n",
    "print(count_usa)\n",
    "print(count_italy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi = {}\n",
    "for key,value in poi_names.items():\n",
    "    if(poi_names[key]>500):\n",
    "        poi[key] = value\n",
    "print(poi)\n",
    "data = {}\n",
    "data[\"count_covid\"] = count_covid\n",
    "data[\"count_non_covid\"] = count_non_covid\n",
    "data[\"poi_names\"] = poi\n",
    "data[\"count_india\"] = count_india\n",
    "data[\"count_usa\"] = count_usa\n",
    "data[\"count_italy\"] = count_italy\n",
    "with open('static.json','w') as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in range(1,len(result)):\n",
    "    try:\n",
    "        x = str(result[i])\n",
    "        x = x.replace('\\\\','/')\n",
    "        with open(x,encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "        if 'JSON_IR_ROHIT' not in x:\n",
    "            data = data.replace('}{','},{')\n",
    "            data = '['+data+']'\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        else:\n",
    "            posts = json.loads(data)\n",
    "    except:\n",
    "        print(result[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "from google_trans_new import google_translator\n",
    "\n",
    "def sentiment_score_function(text):\n",
    "    #gs = google_translator()\n",
    "    #text = gs.translate(text,'en')\n",
    "    return analyser.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "json_dataframe = pd.DataFrame()\n",
    "\n",
    "simple_list = []\n",
    "created_at = []\n",
    "full_text = []\n",
    "tweet_id = []\n",
    "user = []\n",
    "entities = []\n",
    "verified = []\n",
    "retweet_count = []\n",
    "favorite_count = []\n",
    "influencer_score = []\n",
    "sentiment_score = []\n",
    "country = []\n",
    "\n",
    "for i in range(1,len(result)):\n",
    "\n",
    "    try:\n",
    "        x = str(result[i])\n",
    "        x = x.replace('\\\\','/')\n",
    "        with open(x,encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "        if 'JSON_IR_ROHIT' not in x:\n",
    "            data = data.replace('}{','},{')\n",
    "            data = '['+data+']'\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        elif 'static' not in x:\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        for post in posts:\n",
    "            post = json.dumps(post)\n",
    "            post = json.loads(post)\n",
    "            created_at.append(post['created_at'])\n",
    "            full_text.append(post['full_text'])\n",
    "            tweet_id.append(post['id'])\n",
    "            entities.append(post['entities'])\n",
    "            verified.append(post['verified'])\n",
    "            retweet_count.append(post['retweet_count'])\n",
    "            favorite_count.append(post['favorite_count'])\n",
    "            country.append(post['country'])\n",
    "            influencer_score.append(post['favorite_count']+post['retweet_count'])\n",
    "            sentiment_score.append(sentiment_score_function(post['full_text']))\n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influencer_score(v1,v2,v3):\n",
    "    if(v3):\n",
    "        return (v1+v2)**2\n",
    "    else:\n",
    "        return v1+v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(result)):\n",
    "    try:\n",
    "        x = str(result[i])\n",
    "        x = x.replace('\\\\','/')\n",
    "        with open(x,encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "            \n",
    "        if 'JSON_IR_ROHIT' not in x:\n",
    "            data = data.replace('}{','},{')\n",
    "            data = '['+data+']'\n",
    "            posts = json.loads(data)\n",
    "        \n",
    "        elif 'static' not in x:\n",
    "            posts = json.loads(data)\n",
    "            \n",
    "        \n",
    "        df2 = pd.DataFrame(posts)\n",
    "        df2 = df2[['created_at','full_text','id','user','entities','retweet_count','favorite_count','country']]\n",
    "        if(df2.get(\"user\").get(\"verified\")):\n",
    "            df2['influencer_score'] = (df2['favorite_count']+df2['retweet_count'])**2\n",
    "        else:\n",
    "            df2['influencer_score'] = df2['favorite_count']+df2['retweet_count']\n",
    "    #df2['nScore'] = df2['influencer_score']/df2['influencer_score'].max()\n",
    "        if(df.shape==(0,0)):\n",
    "            df = df2\n",
    "        else:\n",
    "            df = pd.concat([df,df2])\n",
    "\n",
    "        df.drop_duplicates(subset=['id'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df.to_json(orient='records')[1:-1]\n",
    "out = '[' + out + ']'\n",
    "\n",
    "with open('outfile.json','w') as f:\n",
    "    json.dump(json.loads(out),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('final.csv')\n",
    "#data.to_json('final_json.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {}\n",
    "import ast\n",
    "import json\n",
    "for i in range(0,len(data)):\n",
    "    y = json.loads(json.dumps(ast.literal_eval(data['user'][i])))\n",
    "    \n",
    "    if ('corona' or 'coronavirus' or 'covid' or 'policy') in data['full_text'][i].lower():\n",
    "        \n",
    "        if(y['screen_name']!=None):\n",
    "            if(y['verified']):\n",
    "                if y['screen_name']+str(data['created_at'][i].split('T')[0]) not in x:\n",
    "                    x[y['screen_name']+str(data['created_at'][i].split('T')[0])]=1\n",
    "                else:\n",
    "                    x[y['screen_name']+str(data['created_at'][i].split('T')[0])]+=1\n",
    "    else:\n",
    "        if(y['verified']):\n",
    "            if(y['screen_name']!=None):\n",
    "                if y['screen_name']+'-non'+str(data['created_at'][i].split('T')[0]) not in x:\n",
    "                    x[y['screen_name']+'-non'+str(data['created_at'][i].split('T')[0])]=1\n",
    "                else:\n",
    "                    x[y['screen_name']+'-non'+str(data['created_at'][i].split('T')[0])]+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in sorted(x.items()):\n",
    "    if key!=None:\n",
    "        if value>10:\n",
    "            print(key+' '+str(x[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
