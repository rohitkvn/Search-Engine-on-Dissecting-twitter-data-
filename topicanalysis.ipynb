{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "v9xEcCpPVimq",
    "outputId": "16d45fab-f65a-4603-df43-9ae3c879b1f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>entities</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>country</th>\n",
       "      <th>influencer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-18T15:00:00Z</td>\n",
       "      <td>איחולים לבביים לידידי @netanyahu נתניהו, לאזרח...</td>\n",
       "      <td>1306969908115394561</td>\n",
       "      <td>{'id': 18839785, 'id_str': '18839785', 'name':...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>2157</td>\n",
       "      <td>20115</td>\n",
       "      <td>India</td>\n",
       "      <td>22272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-18T15:00:00Z</td>\n",
       "      <td>Warm Rosh Hashanah greetings to my friend @net...</td>\n",
       "      <td>1306969864217690112</td>\n",
       "      <td>{'id': 18839785, 'id_str': '18839785', 'name':...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>2441</td>\n",
       "      <td>20117</td>\n",
       "      <td>India</td>\n",
       "      <td>22558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-18T11:00:00Z</td>\n",
       "      <td>मैं देश के किसानों को स्पष्ट संदेश देना चाहता ...</td>\n",
       "      <td>1306915656600702976</td>\n",
       "      <td>{'id': 18839785, 'id_str': '18839785', 'name':...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>10668</td>\n",
       "      <td>43452</td>\n",
       "      <td>India</td>\n",
       "      <td>54120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-18T11:00:00Z</td>\n",
       "      <td>देशभर के किसानों को कृषि सुधार विधेयकों के पार...</td>\n",
       "      <td>1306915613101535232</td>\n",
       "      <td>{'id': 18839785, 'id_str': '18839785', 'name':...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>4327</td>\n",
       "      <td>17658</td>\n",
       "      <td>India</td>\n",
       "      <td>21985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-18T11:00:00Z</td>\n",
       "      <td>आज हाजीपुर-घोसवर-वैशाली नई रेल लाइन के शुरू हो...</td>\n",
       "      <td>1306915261681790978</td>\n",
       "      <td>{'id': 18839785, 'id_str': '18839785', 'name':...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>1828</td>\n",
       "      <td>7947</td>\n",
       "      <td>India</td>\n",
       "      <td>9775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at                                          full_text  \\\n",
       "0  2020-09-18T15:00:00Z  איחולים לבביים לידידי @netanyahu נתניהו, לאזרח...   \n",
       "1  2020-09-18T15:00:00Z  Warm Rosh Hashanah greetings to my friend @net...   \n",
       "2  2020-09-18T11:00:00Z  मैं देश के किसानों को स्पष्ट संदेश देना चाहता ...   \n",
       "3  2020-09-18T11:00:00Z  देशभर के किसानों को कृषि सुधार विधेयकों के पार...   \n",
       "4  2020-09-18T11:00:00Z  आज हाजीपुर-घोसवर-वैशाली नई रेल लाइन के शुरू हो...   \n",
       "\n",
       "                    id                                               user  \\\n",
       "0  1306969908115394561  {'id': 18839785, 'id_str': '18839785', 'name':...   \n",
       "1  1306969864217690112  {'id': 18839785, 'id_str': '18839785', 'name':...   \n",
       "2  1306915656600702976  {'id': 18839785, 'id_str': '18839785', 'name':...   \n",
       "3  1306915613101535232  {'id': 18839785, 'id_str': '18839785', 'name':...   \n",
       "4  1306915261681790978  {'id': 18839785, 'id_str': '18839785', 'name':...   \n",
       "\n",
       "                                            entities  retweet_count  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...           2157   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...           2441   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...          10668   \n",
       "3  {'hashtags': [], 'symbols': [], 'user_mentions...           4327   \n",
       "4  {'hashtags': [], 'symbols': [], 'user_mentions...           1828   \n",
       "\n",
       "   favorite_count country  influencer_score  \n",
       "0           20115   India             22272  \n",
       "1           20117   India             22558  \n",
       "2           43452   India             54120  \n",
       "3           17658   India             21985  \n",
       "4            7947   India              9775  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#reviews_datasets = pd.read_json('influencer_score_covid19 AND government AND lockdown.json')\n",
    "reviews_datasets = pd.read_csv('C:/Users/Krish/Desktop/final.csv')\n",
    "reviews_datasets = reviews_datasets.head(10000)\n",
    "#print(reviews_datasets)\n",
    "reviews_datasets.dropna()\n",
    "reviews_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = []\n",
    "for x in stopwords.words('english'):\n",
    "    stop_words.append(x)\n",
    "for y in stopwords.words('italian'):\n",
    "    stop_words.append(y)\n",
    "for z in stopwords.words('hindi'):\n",
    "    stop_words.append(z)\n",
    "my_stopwords = frozenset(stop_words)\n",
    "#print(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1n_4a7R7XXjQ",
    "outputId": "d6de723a-4524-47d3-df8c-153bea70129a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for your touching wishes. https://t.co/7pUajtQM9P'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_datasets['full_text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_tweets = []\n",
    "import json\n",
    "import ast\n",
    "for i in range(len(reviews_datasets)):\n",
    "    x = reviews_datasets['user'][i]\n",
    "    y = json.loads(json.dumps(ast.literal_eval(x)))\n",
    "    #if(y['verified']):\n",
    "    poi_tweets.append( (reviews_datasets['full_text'][i]).replace('SCREEN_NAME',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "S4dLUX2OXlI9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['अपन', 'अभ', 'आद', 'इत', 'इन', 'इनक', 'इसक', 'इसम', 'उनक', 'उसक', 'एव', 'ऐस', 'करत', 'करन', 'कह', 'कहत', 'गय', 'जह', 'तन', 'तर', 'दब', 'दर', 'धर', 'नक', 'नस', 'नह', 'पहल', 'बन', 'बह', 'यत', 'यद', 'रख', 'रह', 'लक', 'वर', 'वग़', 'सकत', 'सबस', 'सभ', 'सर'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words=my_stopwords)\n",
    "doc_term_matrix = count_vect.fit_transform(poi_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ML_KdF7FYSHb",
    "outputId": "fea925ef-1fa0-4ce5-cf02-e75376d82303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1173x2210 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16217 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vl5VHpnVZOV8",
    "outputId": "d49a2393-e1ef-486c-c958-920f9e25ee92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1ihyqxQZaSn",
    "outputId": "f2893dcd-a007-4300-df98-56fa8fba1a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "રક\n",
      "virtual\n",
      "post\n",
      "issued\n",
      "st\n",
      "addressing\n",
      "death\n",
      "रमण\n",
      "abundance\n",
      "शक\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "    print(count_vect.get_feature_names()[random_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "HmHNCFppZgwY"
   },
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "SjU7LO45Zo_a"
   },
   "outputs": [],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e59NoiroZ0s2",
    "outputId": "152428f5-35a2-40a2-bd49-35c176d0c701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india\n",
      "life\n",
      "rt\n",
      "covid\n",
      "ji\n",
      "may\n",
      "covid19\n",
      "government\n",
      "https\n",
      "co\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41BXSGQ1Z5lH",
    "outputId": "4e221f73-3a69-4659-e546-9acfbbff4e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['india', 'life', 'rt', 'covid', 'ji', 'may', 'covid19', 'government', 'https', 'co']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['ji', 'people', 'thanks', '19', 'covid', 'india', 'wishes', 'thank', 'https', 'co']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['आभ', 'well', 'nation', 'यव', 'धन', 'आपक', 'बह', 'india', 'https', 'co']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['कल', 'अपन', 'मन', 'सरक', 'जन', 'रह', 'हम', 'रत', 'https', 'co']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['shri', 'condolences', 'people', 'ji', 'sector', 'family', 'would', 'education', 'co', 'https']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhMtB0CMaUqL",
    "outputId": "87982a4f-e7d1-48a0-d50d-8dcc7fe276b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1173, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ogcXPJqFaazj"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-e1d5eb2dd80d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreviews_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Topic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3000\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "reviews_datasets['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "SCUd3PkGaham",
    "outputId": "d04e6ece-a529-4ff0-d42e-d1679d7cd967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_datasets['Topic'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b9c01bdd1d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'it'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "spacy.load('hi')\n",
    "spacy.load('it')\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.hi import Hindi\n",
    "from spacy.lang.hi import Italian\n",
    "english_parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"source\": {\"id\": null, \"name\": \"Lifehacker.com\"}, \"author\": \"Aisha Jordan\", \"title\": \"How to Celebrate Diwali\", \"description\": \"Diwali, a five-day-long \\u201cfestival of lights\\u201d that celebrates the triumph of good over evil, began yesterday. The holiday emerged from the Hindu religion, but has become a cultural event around the world. We could all use a little celebration of triumph over e\\u2026\", \"url\": \"https://lifehacker.com/how-to-celebrate-diwali-1845666878\", \"urlToImage\": \"https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/zrr7tme5jm9sf7ofjqhc.jpg\", \"publishedAt\": \"2020-11-13T21:15:00Z\", \"content\": \"Diwali, a five-day-long festival of lights that celebrates the triumph of good over evil, began yesterday. The holiday emerged from the Hindu religion, but has become a cultural event around the worl\\u2026 [+1951 chars]\"}, {\"source\": {\"id\": \"engadget\", \"name\": \"Engadget\"}, \"author\": \"Daniel Cooper\", \"title\": \"Google Maps no longer has to guess how crowded your transit line is\", \"description\": \"These days, finding out when a public space or subway car is crowded isn\\u2019t just for convenience, it could potentially save lives. That\\u2019s why Google is talking up its Maps update which now offers real-time crowding information for your local transit line. In a\\u2026\", \"url\": \"https://www.engadget.com/google-maps-transit-takeout-real-time-data-110005147.html\", \"urlToImage\": \"https://o.aolcdn.com/images/dims?resize=1200%2C630&crop=1200%2C630%2C0%2C0&quality=95&image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2020-11%2F5cebd9f0-28be-11eb-bfff-bcc838f4a222&client=amp-blogside-v2&signature=249914102d8b0f92e4f9249490a15d6d4a462d5e\", \"publishedAt\": \"2020-11-17T11:00:05Z\", \"content\": \"Since plenty of us are spending the next few months indoors, Google is also offering real-time takeout tracking. If you\\u2019ve ordered with the Google Maps app, and you\\u2019re based in the US, Canada, German\\u2026 [+568 chars]\"}, {\"source\": {\"id\": \"engadget\", \"name\": \"Engadget\"}, \"author\": \"Kris Holt\", \"title\": \"Amazon workers plan Black Friday strikes and protests in 15 countries\", \"description\": \"Amazon warehouse workers in several countries are planning to carry out strikes and protests on Black Friday, one of the biggest sales events of the year for the company. Among other things, they'll call on Amazon to improve pay and safety conditions, and res\\u2026\", \"url\": \"https://www.engadget.com/amazon-black-friday-strikes-protests-181200444.html\", \"urlToImage\": \"https://o.aolcdn.com/images/dims?resize=1200%2C630&crop=1200%2C630%2C0%2C0&quality=95&image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2020-11%2F87beeb80-3008-11eb-beff-79c54dd825fd&client=amp-blogside-v2&signature=d0ec6e215b4723724084c2f9c08fb55093f56033\", \"publishedAt\": \"2020-11-26T18:12:00Z\", \"content\": \"This time around, protests, strikes and other actions will take place in the US, the UK, Mexico, Brazil, India, Australia and nine other nations. The coordinated effort is called #MakeAmazonPay and i\\u2026 [+996 chars]\"}, {\"source\": {\"id\": \"wired\", \"name\": \"Wired\"}, \"author\": \"Daniel Oberhaus\", \"title\": \"Fireball Is Werner Herzog\\u2019s Ode to Space Rocks\", \"description\": \"A new documentary from the German auteur examines the influence of meteorites on cultures around the world.\", \"url\": \"https://www.wired.com/story/fireball-herzog-meteorite-documentary/\", \"urlToImage\": \"https://media.wired.com/photos/5faad18b446b4639b3d5b89d/191:100/w_1280,c_limit/Culture_FIREBALL-1.jpg\", \"publishedAt\": \"2020-11-12T14:00:00Z\", \"content\": \"The Ramgarh crater in northern India was formed millions of years ago when a large meteorite crashed into Earth. But it wasnt until the 19th century that scientists began to believe it was an impact \\u2026 [+4002 chars]\"}, {\"source\": {\"id\": \"wired\", \"name\": \"Wired\"}, \"author\": \"Justin Sherman\", \"title\": \"Biden Must Repair\\u2014and Reinvigorate\\u2014Tech Diplomacy\", \"description\": \"The administration\\u2019s nomination of Antony Blinken is a good start. But mending the damage of the past four years will require a complete reorientation.\", \"url\": \"https://www.wired.com/story/biden-must-repair-and-reinvigorate-tech-diplomacy/\", \"urlToImage\": \"https://media.wired.com/photos/5fbd6d03058b2614ff621b13/191:100/w_1280,c_limit/OpEd-Tony-Blinken-1287465337.jpg\", \"publishedAt\": \"2020-11-25T14:00:00Z\", \"content\": \"The Biden-Harris administration has officially named Antony Blinken as its pick for secretary of state. In kind with other nominees announced in the past few days, Blinken is an experienced civil ser\\u2026 [+4157 chars]\"}, {\"source\": {\"id\": \"the-verge\", \"name\": \"The Verge\"}, \"author\": \"Loren Grush\", \"title\": \"International coalition of activists launches protest against Amazon\", \"description\": \"On November 27th, or Black Friday, an international group of Amazon workers and climate activists launched a new campaign called Make Amazon Pay, with stunts planned all over the world. Their goals include better pay for Amazon workers and reducing the compan\\u2026\", \"url\": \"https://www.theverge.com/2020/11/27/21722421/make-amazon-pay-protest-campaign-black-friday\", \"urlToImage\": \"https://cdn.vox-cdn.com/thumbor/bFFK53WuA2FojTJ74IZ1kFEE9Z8=/0x457:4032x2568/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/22125105/002.jpg\", \"publishedAt\": \"2020-11-27T14:54:36Z\", \"content\": \"The \\u201cMake Amazon Pay\\u201d logo projected onto Amazon\\u2019s campus in Hyderabad, India. | Image: Make Amazon Pay campaign\\r\\n\\n \\n\\n An international group of climate activists and Amazon warehouse workers have la\\u2026 [+3939 chars]\"}, {\"source\": {\"id\": \"the-verge\", \"name\": \"The Verge\"}, \"author\": \"Casey Newton\", \"title\": \"What Twitter Fleets signals about the future of the company\", \"description\": \"Yesterday, Twitter introduced a new ephemeral post type called \\u201cfleets,\\u201d and is currently testing new audio features. Can the company make a space for healthy conversations? And can it make amends with its history of harassment?\", \"url\": \"https://www.theverge.com/21573380/twitter-fleets-launch-stories-spaces-future\", \"urlToImage\": \"https://cdn.vox-cdn.com/thumbor/1zez70uv4JdlHC48r4RTKuJo7kw=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/20086270/acastro_200715_1777_twitter_0005.0.jpg\", \"publishedAt\": \"2020-11-18T17:18:38Z\", \"content\": \"With fleets and audio spaces, can the company make a space for healthy conversations?\\r\\nIllustration by Alex Castro / The Verge\\r\\nI.\\r\\nIn March 2017, I drove down to the Instagram offices in Menlo Park \\u2026 [+7391 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Anthony Ha\", \"title\": \"Following its acquisition by BuzzFeed, HuffPost shuts down its Brazil and India editions\", \"description\": \"HuffPost is becoming part of BuzzFeed, but HuffPost India and HuffPost Brasil will not be making the transition \\u2014 both sites are shutting down today. \\u201cToday is @huffpostIndia\\u2019s last day,\\u201d tweeted the team\\u2019s editor in chief Aman Sethi. \\u201cPound for pound, story \\u2026\", \"url\": \"http://techcrunch.com/2020/11/24/huffpost-india-brasil-shutdown/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/11/GettyImages-1039635324.jpg?w=610\", \"publishedAt\": \"2020-11-24T16:50:39Z\", \"content\": \"HuffPost is becoming part of BuzzFeed, but HuffPost India and HuffPost Brasil will not be making the transition both sites are shutting down today.\\r\\n\\u201cToday is @huffpostIndias last day,\\u201d tweeted the t\\u2026 [+1155 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"Payments app True Balance raises $28 million to reach more underbanked users in India\", \"description\": \"True Balance, a South Korean startup which runs an eponymous financial services app aimed at tens of millions of users in small cities and towns in India, said on Wednesday it has raised $28 million in a new financing round and expects to turn a profit next y\\u2026\", \"url\": \"http://techcrunch.com/2020/11/18/payments-app-true-balance-raises-28-million-to-reach-more-underbanked-users-in-india/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2019/05/truebalance.jpg?w=764\", \"publishedAt\": \"2020-11-18T09:03:02Z\", \"content\": \"True Balance, a South Korean startup which runs an eponymous financial services app aimed at tens of millions of users in small cities and towns in India, said on Wednesday it has raised $28 million \\u2026 [+3000 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"Police case filed against Netflix executives in India over \\u2018A Suitable Boy\\u2019 kissing scene\", \"description\": \"Netflix, which has invested more than $500 million to gain a foothold in India in recent years, is slowly finding out just about what all could upset some people in the world\\u2019s second-largest internet market: Apparently everything. A police case has been file\\u2026\", \"url\": \"http://techcrunch.com/2020/11/24/police-case-filed-against-netflix-executives-in-india-over-a-suitable-boy-kissing-scene/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/11/GettyImages-1287315851.jpg?w=559\", \"publishedAt\": \"2020-11-25T00:27:06Z\", \"content\": \"Netflix, which has invested more than $500 million to gain a foothold in India in recent years, is slowly finding out just about what all could upset some people in the worlds second-largest internet\\u2026 [+2321 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"India\\u2019s insurance platform Turtlemint raises $30 million\", \"description\": \"Turtlemint, an Indian startup that is helping consumers identify and purchase the most appropriate insurance policies for them, has raised $30 million in a new financing round as it looks to reach more users in small cities and towns in the world\\u2019s second lar\\u2026\", \"url\": \"http://techcrunch.com/2020/11/17/india-insurance-startup-turtlemint-raises-30-million/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/11/GettyImages-536118200-1.jpg?w=599\", \"publishedAt\": \"2020-11-17T10:31:02Z\", \"content\": \"Turtlemint, an Indian startup that is helping consumers identify and purchase the most appropriate insurance policies for them, has raised $30 million in a new financing round as it looks to reach mo\\u2026 [+2513 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"Reliance Retail buys Urban Ladder for $24.4 million\", \"description\": \"Reliance Retail has acquired a majority stake in furniture and decor platform Urban Ladder, making a broader push into e-commerce as the largest retail chain in India gears up to fight Amazon and Flipkart. In a filing to the local stock exchange, Reliance Ret\\u2026\", \"url\": \"http://techcrunch.com/2020/11/14/reliance-retail-buys-urban-ladder-for-24-4-million/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/10/GettyImages-1227124558.jpg?w=600\", \"publishedAt\": \"2020-11-15T06:35:46Z\", \"content\": \"Reliance Retail has acquired a majority stake in furniture and decor platform Urban Ladder, making a broader push into e-commerce as the largest retail chain in India gears up to fight Amazon and Fli\\u2026 [+2100 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"Tiger Global invests in India\\u2019s Unacademy at $2 billion valuation\", \"description\": \"Unacademy, an online learning platform in India, today announced it has raised a fresh investment round from Tiger Global Management and Dragoneer Investment Group. The funding round, the size of which was not disclosed, valued the Bangalore-based startup at \\u2026\", \"url\": \"http://techcrunch.com/2020/11/25/tiger-global-invests-in-india-unacademy-at-2-billion-valuation/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2018/07/L-R-Roman-Saini-Gaurav-Munjal-Hemesh-Singh.jpg?w=600\", \"publishedAt\": \"2020-11-25T12:49:44Z\", \"content\": \"Unacademy, an online learning platform in India, has added two more marquee investors to its cap table. The Bangalore-based startup said on Wednesday it has raised new funds from\\u00a0Tiger Global Managem\\u2026 [+819 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Manish Singh\", \"title\": \"Jio Platforms backs SF-based AR gaming startup Krikey\", \"description\": \"Jio Platforms, the biggest telecom operator in India and which has raised over $20 billion from Facebook, Google and other high-profile investors this year, is leading a financing round of a San Francisco-based startup that develops augmented-reality mobile g\\u2026\", \"url\": \"http://techcrunch.com/2020/12/02/jio-platforms-backs-sf-based-ar-gaming-startup-krikey/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/12/krikey-jio.jpg?w=709\", \"publishedAt\": \"2020-12-02T13:59:44Z\", \"content\": \"Jio Platforms, the biggest telecom operator in India and which has raised over $20 billion from Facebook, Google and other high-profile investors this year, is leading a financing round of a San Fran\\u2026 [+1843 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Zack Whittaker\", \"title\": \"Microsoft says hackers backed by Russia and North Korea targeted COVID-19 vaccine makers\", \"description\": \"Microsoft has revealed that hackers backed by Russia and North Korea have targeted pharmaceutical companies involved in the COVID-19 vaccine development efforts. The technology giant said Friday that the attacks targeted seven companies in the U.S., Canada, F\\u2026\", \"url\": \"http://techcrunch.com/2020/11/13/microsoft-russia-north-korea-hackers-coronavirus-vaccine/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/11/GettyImages-1229305401.jpg?w=600\", \"publishedAt\": \"2020-11-13T14:00:13Z\", \"content\": \"Microsoft has revealed that hackers backed by Russia and North Korea have targeted pharmaceutical companies involved in the COVID-19 vaccine development efforts.\\r\\nThe technology giant said Friday tha\\u2026 [+2595 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Rita Liao\", \"title\": \"How China\\u2019s Realme sold 50 million phones in just over 2 years\", \"description\": \"Starting a new phone brand in 2018 might seem too late in an already crowded market, but Sky Li was convinced that consumers between 18-25 years old were largely under-served \\u2014 they needed something that was both affordable and cool. A few months after Li fou\\u2026\", \"url\": \"http://techcrunch.com/2020/11/20/realme-profile/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/11/campus-concert-e1605863576478.png?w=752\", \"publishedAt\": \"2020-11-20T09:40:37Z\", \"content\": \"Starting a new phone brand in 2018 might seem too late in an already crowded market, but Sky Li was convinced that consumers between 18-25 years old were largely underserved \\u2014 they needed something t\\u2026 [+7092 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Sarah Perez\", \"title\": \"This Week in Apps: Snapchat clones TikTok, India bans 43 Chinese apps, more data on App Store commission changes\", \"description\": \"Welcome back to This Week in\\u00a0Apps, the\\u00a0TechCrunch series that recaps the latest in mobile OS news, mobile applications, and the overall app economy. The app industry is as hot as ever, with\\u00a0a record 204 billion downloads and $120 billion in consumer spending \\u2026\", \"url\": \"http://techcrunch.com/2020/11/29/this-week-in-apps-snapchat-clones-tiktok-india-bans-43-chinese-apps-more-data-on-app-store-commission-changes/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/10/this-week-in-apps-splash-2.png?w=753\", \"publishedAt\": \"2020-11-29T14:00:28Z\", \"content\": \"Welcome back to This Week in\\u00a0Apps, the\\u00a0TechCrunch series that recaps the latest in mobile OS news, mobile applications, and the overall app economy.\\r\\nThe app industry is as hot as ever, with\\u00a0a record\\u2026 [+7222 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Romain Dillet\", \"title\": \"Foxconn could move some iPad and MacBook production to Vietnam\", \"description\": \"Following a request from Apple, Foxconn could be shifting production out of China for some iPad and MacBook models according to a report from Reuters. The new assembly lines would be based in Vietnam. As a recent investigation from The Information highlighted\\u2026\", \"url\": \"http://techcrunch.com/2020/11/26/foxconn-could-move-some-ipad-and-macbook-production-to-vietnam/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2018/10/3Q5A5611.jpg?w=600\", \"publishedAt\": \"2020-11-26T16:10:54Z\", \"content\": \"Following a request from Apple, Foxconn could be shifting production out of China for some iPad and MacBook models according to a report from Reuters. The new assembly lines would be based in Vietnam\\u2026 [+1032 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Anthony Ha\", \"title\": \"Daily Crunch: Verizon sells HuffPost to BuzzFeed\", \"description\": \"HuffPost has a new owner, Facebook says its misinformation-fighting AI is getting smarter and Affirm files to go public. This is your Daily Crunch for November 19, 2020. The big story: Verizon sells HuffPost to BuzzFeed TechCrunch\\u2019s parent company Verizon Med\\u2026\", \"url\": \"http://techcrunch.com/2020/11/19/verizon-sells-huffpost-to-buzzfeed/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2019/02/GettyImages-1071861718.jpg?w=600\", \"publishedAt\": \"2020-11-19T23:10:22Z\", \"content\": \"HuffPost has a new owner, Facebook says its misinformation-fighting AI is getting smarter and Affirm files to go public. This is your Daily Crunch for November 19, 2020.\\r\\nThe big story: Verizon sells\\u2026 [+3245 chars]\"}, {\"source\": {\"id\": \"techcrunch\", \"name\": \"TechCrunch\"}, \"author\": \"Anthony Ha\", \"title\": \"Daily Crunch: Twitter will bring back verification\", \"description\": \"Twitter prepares to hand out more blue checkmarks, YouTube suspends OANN and Discord is raising a big funding round. This is your Daily Crunch for November 24, 2020. The big story: Twitter will bring back verification Twitter paused its blue checkmark verific\\u2026\", \"url\": \"http://techcrunch.com/2020/11/24/daily-crunch-twitter-will-bring-back-verification/\", \"urlToImage\": \"https://techcrunch.com/wp-content/uploads/2020/01/twitter-CES-2020-05.jpg?w=711\", \"publishedAt\": \"2020-11-24T23:11:39Z\", \"content\": \"Twitter prepares to hand out more blue checkmarks, YouTube suspends OANN and Discord is raising a big funding round. This is your Daily Crunch for November 24, 2020.\\r\\nThe big story: Twitter will brin\\u2026 [+3298 chars]\"}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = ('http://newsapi.org/v2/everything?'\n",
    "       'q=India&'\n",
    "       'from=2020-11-12&'\n",
    "       'sortBy=popularity&'\n",
    "       'apiKey=8ab0444ae6e74d0eb01c52f941647514')\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "print(json.dumps(response.json()['articles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "en_stop = list(nltk.corpus.stopwords.words('english'))\n",
    "en_stop.append('SCREEN_NAME')\n",
    "en_stop = set(en_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "text_data = []\n",
    "for line in poi_tweets:\n",
    "    tokens = prepare_text_for_lda(line)\n",
    "    if random.random() > .99:\n",
    "        try:\n",
    "            text_data.append(tokens)\n",
    "        except:\n",
    "            text_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.026*\"सम्मान\" + 0.015*\"unemployment\" + 0.014*\"covid19\" + 0.014*\"government\"')\n",
      "(1, '0.029*\"coronavirus\" + 0.026*\"सरकार\" + 0.023*\"covid19\" + 0.023*\"कोरोना\"')\n",
      "(2, '0.099*\"covid19\" + 0.096*\"dangerous\" + 0.096*\"pandemic\" + 0.095*\"unemployment\"')\n",
      "(3, '0.036*\"सरकार\" + 0.029*\"lockd\" + 0.029*\"कितने\" + 0.029*\"आंकड़े\"')\n",
      "(4, '0.075*\"covid19\" + 0.059*\"people\" + 0.055*\"effort\" + 0.055*\"concern\"')\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model5.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.116*\"17baje17minute\" + 0.099*\"unemployment\" + 0.099*\"dangerous\" + 0.096*\"covid19\"')\n",
      "(1, '0.026*\"covid19\" + 0.026*\"india\" + 0.026*\"prime\" + 0.026*\"minister\"')\n",
      "(2, '0.037*\"government\" + 0.025*\"सरकार\" + 0.025*\"number\" + 0.025*\"case\"')\n",
      "(3, '0.039*\"कोरोना\" + 0.026*\"सरकार\" + 0.026*\"संक्रमण\" + 0.014*\"coronavirus\"')\n",
      "(4, '0.042*\"fail\" + 0.022*\"pandemic\" + 0.022*\"coronavirus\" + 0.022*\"incompetence\"')\n",
      "(5, '0.030*\"सरकार\" + 0.030*\"covid19\" + 0.016*\"government\" + 0.016*\"ग्रामीण\"')\n",
      "(6, '0.031*\"covid19\" + 0.031*\"change\" + 0.031*\"pandemic\" + 0.016*\"effort\"')\n",
      "(7, '0.096*\"covid19\" + 0.089*\"pandemic\" + 0.089*\"unemployment\" + 0.089*\"youngster\"')\n",
      "(8, '0.102*\"covid19\" + 0.079*\"people\" + 0.074*\"effort\" + 0.074*\"concern\"')\n",
      "(9, '0.056*\"सरकार\" + 0.029*\"सम्मान\" + 0.029*\"मंत्री\" + 0.029*\"कितने\"')\n"
     ]
    }
   ],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 10, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model10.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('model10.gensim')\n",
    "import pyLDAvis.gensim\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)\n",
    "pyLDAvis.save_html(lda_display, 'lda.html')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "topicanalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
